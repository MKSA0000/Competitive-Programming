{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3c67ec52ed15e0f818407aaecc706382b0f2c1ca12664c8d998db1b3d5d17ce4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Model):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = Dense(hidden_dim,activation='sigmoid')\n",
    "        self.l2 = Dense(output_dim,activation='sigmoid')\n",
    "    \n",
    "    def call(self,x):\n",
    "        h = self.l1(x)\n",
    "        y = self.l2(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 18.153739392757416]\n",
      "[2, 17.146430134773254]\n",
      "[3, 16.422325909137726]\n",
      "[4, 15.800965785980225]\n",
      "[5, 15.259121835231781]\n",
      "[6, 14.734732508659363]\n",
      "[7, 14.255744636058807]\n",
      "[8, 13.820853531360626]\n",
      "[9, 13.412509262561798]\n",
      "[10, 13.037162274122238]\n",
      "[11, 12.677453428506851]\n",
      "[12, 12.34906181693077]\n",
      "[13, 12.053036451339722]\n",
      "[14, 11.770999103784561]\n",
      "[15, 11.523473352193832]\n",
      "[16, 11.319578349590302]\n",
      "[17, 11.120020121335983]\n",
      "[18, 10.942359983921051]\n",
      "[19, 10.779083460569382]\n",
      "[20, 10.65008920431137]\n",
      "[21, 10.54791758954525]\n",
      "[22, 10.431716367602348]\n",
      "[23, 10.317040264606476]\n",
      "[24, 10.24480353295803]\n",
      "[25, 10.15718786418438]\n",
      "[26, 10.112668424844742]\n",
      "[27, 10.05280590057373]\n",
      "[28, 9.970908209681511]\n",
      "[29, 9.924373105168343]\n",
      "[30, 9.893476843833923]\n",
      "[31, 9.850363597273827]\n",
      "[32, 9.816470548510551]\n",
      "[33, 9.768211424350739]\n",
      "[34, 9.74425257742405]\n",
      "[35, 9.719978675246239]\n",
      "[36, 9.693762242794037]\n",
      "[37, 9.679912835359573]\n",
      "[38, 9.669430986046791]\n",
      "[39, 9.645051956176758]\n",
      "[40, 9.606713145971298]\n",
      "[41, 9.612317502498627]\n",
      "[42, 9.585978507995605]\n",
      "[43, 9.581279650330544]\n",
      "[44, 9.544439256191254]\n",
      "[45, 9.543164521455765]\n",
      "[46, 9.565481886267662]\n",
      "[47, 9.534792512655258]\n",
      "[48, 9.510749876499176]\n",
      "[49, 9.50813639163971]\n",
      "[50, 9.505354538559914]\n",
      "[51, 9.508445218205452]\n",
      "[52, 9.500393904745579]\n",
      "[53, 9.483820721507072]\n",
      "[54, 9.488153971731663]\n",
      "[55, 9.484348453581333]\n",
      "[56, 9.454891473054886]\n",
      "[57, 9.47739753127098]\n",
      "[58, 9.49436491727829]\n",
      "[59, 9.436628013849258]\n",
      "[60, 9.439302295446396]\n",
      "[61, 9.441265724599361]\n",
      "[62, 9.444104701280594]\n",
      "[63, 9.438013643026352]\n",
      "[64, 9.421592429280281]\n",
      "[65, 9.440654337406158]\n",
      "[66, 9.414686664938927]\n",
      "[67, 9.392004400491714]\n",
      "[68, 9.424356997013092]\n",
      "[69, 9.410077467560768]\n",
      "[70, 9.425048589706421]\n",
      "[71, 9.417169973254204]\n",
      "[72, 9.394072115421295]\n",
      "[73, 9.387576550245285]\n",
      "[74, 9.387255787849426]\n",
      "[75, 9.392053112387657]\n",
      "[76, 9.405373960733414]\n",
      "[77, 9.393658116459846]\n",
      "[78, 9.357287153601646]\n",
      "[79, 9.383866339921951]\n",
      "[80, 9.396718017756939]\n",
      "[81, 9.393239945173264]\n",
      "[82, 9.372841283679008]\n",
      "[83, 9.361017242074013]\n",
      "[84, 9.357078239321709]\n",
      "[85, 9.352015376091003]\n",
      "[86, 9.341466918587685]\n",
      "[87, 9.348729893565178]\n",
      "[88, 9.358652338385582]\n",
      "[89, 9.351527065038681]\n",
      "[90, 9.36623366177082]\n",
      "[91, 9.352814227342606]\n",
      "[92, 9.338236540555954]\n",
      "[93, 9.340828776359558]\n",
      "[94, 9.351799130439758]\n",
      "[95, 9.347525179386139]\n",
      "[96, 9.331622570753098]\n",
      "[97, 9.337759479880333]\n",
      "[98, 9.335220120847225]\n",
      "[99, 9.335637100040913]\n",
      "[100, 9.330914728343487]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "criterion = losses.BinaryCrossentropy()\n",
    "optimizer = optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "N = 300\n",
    "x, t = datasets.make_moons(N,noise=0.3)\n",
    "t = t.reshape(N,1)\n",
    "x_train, x_test, t_train, t_test = train_test_split(x, t,test_size=0.2)\n",
    "\n",
    "model = MLP(3,1)\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(t,y)\n",
    "\n",
    "def train_step(x,t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t,preds)\n",
    "    grads = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    x_,t_ = shuffle(x_train,t_train)\n",
    "\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        loss = train_step(x_[start:end], t_[start:end])\n",
    "        train_loss += loss.numpy()\n",
    "    \n",
    "    print([epoch + 1, train_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.31024387, 0.9]\n"
     ]
    }
   ],
   "source": [
    "test_loss = metrics.Mean()\n",
    "test_acc = metrics.BinaryAccuracy()\n",
    "\n",
    "def test_step(x,t):\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t,preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t,preds)\n",
    "    return preds\n",
    "\n",
    "test_step(x_test,t_test)\n",
    "print([test_loss.result().numpy(),test_acc.result().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}